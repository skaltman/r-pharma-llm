---
title: Tool Calling
subtitle: Getting Started with LLM APIs in R
author: R/Pharma 2025
date: 2025-11-03

editor:
  render-on-save: true
---


## Recall: How do LLMs work? {.center}

::: notes
claude: Let's revisit how LLMs work. This is important context for understanding why we need tools.
:::

::: incremental
1. You write some words

2. The LLM writes some more words

3. You _use those words_
:::

::: fragment
_On their own, can LLMs... access the internet? run code? send an email? interact with the world?_
:::

## Let's try it

```{.r}
library(ellmer)

chat <- chat("openai/gpt-4.1-nano")

chat$chat("Who are the keynote speakers at R/Pharma 2025?")
```

```
My training only includes data up until October 2023, and I do not 
have access to real-time updates or event-specific details beyond that. 

For the most accurate and current information about the keynote 
speakers, I recommend visiting the official R/Pharma 2025 
website or checking their latest event announcements.
```

::: notes
claude: Let's try asking about things the model doesn't know. This one fails - the model's training data is old and it doesn't have real-time event information.
:::

## Let's try it

::: notes
claude: This one also fails - the model can't access real-time weather data. No internet connection.
:::

```{.r}
library(ellmer)

chat <- chat("openai/gpt-4.1-nano")

chat$chat("What's the weather like in Utqiagvik, Alaska?")
```

```
I'm unable to provide real-time weather updates.
For the most current weather in Utqiagvik, Alaska,
please check a reliable weather service or app like
Weather.com, AccuWeather, or your local weather provider.
```

## Let's try it

::: notes
claude: But this one... the model actually gives an answer! It's wrong (the date is from its training cutoff), but it shows the model will try to answer with what it knows.
:::

```{.r}
library(ellmer)

chat <- chat("openai/gpt-4.1-nano")

chat$chat("What day is it?")
```

```
Today is October 27, 2023.
```


## Tools {.center}

::: notes
claude: So how do we solve these problems? Tools! Also called functions or function calling.
:::

a.k.a. _functions_, _tool calling_ or _function calling_

::: incremental
* Bring real-time or up-to-date information to the model

* Let the model interact with the world
:::

::: notes
Tools are extra capabilities that you give to the LLM, like the ability to search the R/Pharma 2025 schedule or check the weather.
These capabilities are things that the model can't do on its own.
The goal is to let the model pull in real-time or up-to-date information as needed.

They can also give the model new abilities to take action on behalf of the user.
:::

# How does tool calling work?

::: notes
claude: Let me walk you through exactly how tool calling works step by step. This is the key pattern you need to understand.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-01.excalidraw.svg)

::: notes
The conversation starts with a user sending a message to the chatbot.

In this example, the user asks whether they can go to the pool today - which requires knowing the weather.

The model doesn't have access to real-time weather data, just like we saw earlier with Utqiagvik, Alaska.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-02.excalidraw.svg)

::: notes
Now imagine we've told the LLM that it has access to a tool called `get_weather()`.
Knowing that it needs weather information and doesn't have access to real-time data, the model decides to use the weather tool.

It sends back a message that includes a tool call - basically instructions to call the `get_weather()` function with the appropriate location argument.
The model uses its training data to figure out the right location format (like a ZIP code).
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-03.excalidraw.svg)

::: notes
The programmer takes that tool call message and executes the actual function - in this case, querying a weather API with the location the model specified.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-04.excalidraw.svg)

::: notes
The weather API sends back some data:

* The forecast is mostly sunny
* High of 98ÂºF
* Low of 78ÂºF
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-05.excalidraw.svg)

::: notes
The programmer sends that data back to the LLM.
Note that it's often in a pretty raw format, like JSON.
Not the kind of thing you'd want to read directly unless you're the kind of person who likes reading computer data formats.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-06.excalidraw.svg)

::: notes
The LLM doesn't mind JSON though, so it reads the data and generates a response that _incorporates_ the data from the tool call.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-diagram-07.excalidraw.svg)


## The LLM can't run code by itself!

::: notes
claude: This is crucial to understand - the LLM doesn't execute tools. It just asks you to run them. You're in control!
:::

## {.center style="text-align: center" transition="fade"}

::: notes
claude: The LLM returns a tool call message - it's asking you to run the function. You decide whether to run it.
:::

![](assets/tools-diagram-tool-call.excalidraw.svg)

## {.center style="text-align: center" transition="fade"}

::: notes
claude: The LLM also chooses the arguments for the tool. Here it picks the location based on the conversation.
:::

![](assets/tools-diagram-arg-choice-01.excalidraw.svg)

## {.center style="text-align: center" transition="fade"}

::: notes
claude: It uses its knowledge to fill in the right values - using information from its training data.
:::

![](assets/tools-diagram-arg-choice-02.excalidraw.svg)

## {.center style="text-align: center" transition="fade"}

::: notes
claude: The model can infer details like ZIP codes or coordinates from location names using its training data.
:::

![](assets/tools-diagram-arg-choice-03.excalidraw.svg)

## {.center style="text-align: center" transition="fade"}

::: notes
claude: The LLM can also call multiple tools in a single response if it needs to gather different information.
:::

![](assets/tools-diagram-args-multi.excalidraw.svg)


## Human in the loop {.center}

::: notes
claude: Let me show you a Shiny app where you manually approve each tool call. This shows the pattern clearly - you're always in control.
:::

ðŸ‘©â€ðŸ’» [_demos/18_manual-tools/app.R]{.code .b .purple}

## Wait... I can write code! {.center}

::: notes
claude: But you're programmers! You can automate this. Let me show you how to define tools that run automatically.
:::

ðŸ‘©â€ðŸ’» [_demos/19_tools/19_weather-tool.R]{.code .b .purple}

# Tools in R

## Step 1: Write a (normal) R function

```{.r}
get_weather <- function(zip_code) {
  # use weather API to get weather for that zip
  # ...
}
```

## Step 2: Define the tool

::: notes
claude: Here's the pattern for defining tools in ellmer. You provide the function, a description, and argument types.
:::

```{.r code-line-numbers="|1|2|3|4-11"}
tool_get_weather <- tool(
  tool_fn,
  description = "How and when to use the tool",
  arguments = list(
    .... = type_string(),
    .... = type_integer(),
    .... = type_enum(
      c("choice1", "choice2"),
      required = FALSE
    )
  )
)
```

## Step 2: Define the tool

::: notes
claude: Here's the pattern for defining tools in ellmer. You provide the function, a description, and argument types.
:::

```{.r}
tool_get_weather <- tool(
  get_weather,
  description = 
    "Gets the current weather for a specified zip code",
  arguments = list(
    zip_code = type_string("The zip code.", required = TRUE)
  )
)
```

## Step 3: Register the tool

```{.r}
chat$register_tool(tool_get_weather)
```

# Your Turn `20_quiz-game-2` {.slide-your-turn}

::: notes
claude: Now practice - add a tool to the quiz game that plays sounds. This reinforces the pattern we just learned.
:::

1. I've given you a function that plays a sound when called (`play_sound()`).

1. Your job: give the model the ability to play sounds in the Quiz Show game we made earlier.

1. You will need to fill out the tool definition and register the tool.

{{< countdown 6:00 left=0 bottom="-2em" >}}

::: notes
Follow up question: why send a string back to the LLM that says the sound was played?
:::

## Tools in Shiny

::: notes
claude: When using tools in Shiny apps, remember these key points - tools can interact with your app's reactive state.
:::

::: incremental
* Define the tool function **inside the server**

* You can **update reactive values** in the tool function!

* You can **read reactive values**, _if you `isolate()` reads_. (Be careful!)
:::

## Learn more

::: notes
claude: These are the Posit packages for working with AI. We've focused on ellmer and shinychat today, but there are others for different use cases.
:::

![](assets/posit-ai-packages.png)

## Learn more

**querychat**: <https://github.com/posit-dev/querychat>

* Chat with your data using natural language queries.

**ggbot2**: <https://github.com/tidyverse/ggbot2>

* Talk out loud to create and iterate on plots.

**Databot**: <https://positron.posit.co/databot.html>

* EDA assistant for Positron

**Posit AI newsletter**: <https://posit.co/blog/?post_tag=ai-newsletter>


# Thank you!

